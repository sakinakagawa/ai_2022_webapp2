{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKMqJBBevk4JFJFikXrGlp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakinakagawa/ai_2022_webapp2/blob/main/ai_webapp4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puW5z5ao_KEV",
        "outputId": "0ffd9e96-edfe-4852-854b-14b4670647ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting icrawler\n",
            "  Downloading icrawler-0.6.6-py2.py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from icrawler) (4.6.3)\n",
            "Requirement already satisfied: requests>=2.9.1 in /usr/local/lib/python3.8/dist-packages (from icrawler) (2.25.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from icrawler) (1.15.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from icrawler) (4.9.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from icrawler) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.9.1->icrawler) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.9.1->icrawler) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.9.1->icrawler) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.9.1->icrawler) (1.24.3)\n",
            "Installing collected packages: icrawler\n",
            "Successfully installed icrawler-0.6.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Response status code 403, file https://storage.mainichikirei.jp/images/2018/10/25/20181025dog00m100010000c/001_size9.jpg\n",
            "ERROR:downloader:Response status code 403, file https://storage.mantan-web.jp/images/2016/10/04/20161004dog00m200023000c/001_size9.jpg\n",
            "ERROR:downloader:Exception caught when downloading file https://www.sponichi.co.jp/entertainment/news/2020/07/17/jpeg/20200716s00041000311000p_view.jpg, error: HTTPSConnectionPool(host='www.sponichi.co.jp', port=443): Read timed out. (read timeout=5), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://www.sponichi.co.jp/entertainment/news/2020/07/17/jpeg/20200716s00041000311000p_view.jpg, error: HTTPSConnectionPool(host='www.sponichi.co.jp', port=443): Read timed out. (read timeout=5), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://www.sponichi.co.jp/entertainment/news/2020/07/17/jpeg/20200716s00041000311000p_view.jpg, error: HTTPSConnectionPool(host='www.sponichi.co.jp', port=443): Read timed out. (read timeout=5), remaining retry times: 0\n",
            "ERROR:downloader:Response status code 403, file https://storage.mantan-web.jp/images/2018/01/09/20180109dog00m200024000c/001_size9.jpg\n",
            "ERROR:downloader:Response status code 403, file https://storage.mainichikirei.jp/images/2018/07/03/20180703dog00m100010000c/001_size9.jpg\n",
            "ERROR:downloader:Exception caught when downloading file https://www.sponichi.co.jp/entertainment/news/2021/05/21/jpeg/20210521s00041000056000p_view.jpg, error: HTTPSConnectionPool(host='www.sponichi.co.jp', port=443): Read timed out. (read timeout=5), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://www.sponichi.co.jp/entertainment/news/2021/05/21/jpeg/20210521s00041000056000p_view.jpg, error: HTTPSConnectionPool(host='www.sponichi.co.jp', port=443): Read timed out. (read timeout=5), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://www.sponichi.co.jp/entertainment/news/2021/05/21/jpeg/20210521s00041000056000p_view.jpg, error: HTTPSConnectionPool(host='www.sponichi.co.jp', port=443): Read timed out. (read timeout=5), remaining retry times: 0\n",
            "ERROR:downloader:Response status code 403, file https://sakamobi.com/wp-content/uploads/2020/06/84661e0cf958a4bfd4119cda77b231f8.jpg\n",
            "ERROR:downloader:Response status code 403, file https://bunshun.ismcdn.jp/mwimgs/e/7/1500wm/img_e7940638daadde9999b9d036362f1aff2650287.jpg\n",
            "ERROR:downloader:Response status code 403, file https://cdn.v2ph.com/photos/cGQT1TCsmaGMcn9e.jpg\n",
            "ERROR:downloader:Response status code 403, file https://storage.mantan-web.jp/images/2021/04/15/20210415dog00m200027000c/001_size6.jpg\n",
            "ERROR:downloader:Response status code 403, file https://storage.mantan-web.jp/images/2018/11/02/20181102dog00m200051000c/001_size9.jpg\n",
            "ERROR:downloader:Response status code 403, file https://storage.mainichikirei.jp/images/2018/12/05/20181205dog00m100011000c/001_size9.jpg\n",
            "ERROR:downloader:Response status code 403, file https://storage.mantan-web.jp/images/2016/10/22/20161022dog00m200037000c/006_size9.jpg\n",
            "ERROR:downloader:Response status code 403, file https://storage.mainichikirei.jp/images/2020/08/28/20200828dog00m100001000c/001_size9.jpg\n",
            "ERROR:downloader:Response status code 403, file https://storage.mainichikirei.jp/images/2018/10/25/20181025dog00m100020000c/001_size9.jpg\n",
            "ERROR:downloader:Response status code 403, file https://storage.mainichikirei.jp/images/2016/12/17/20161217dog00m100001000c/001_size9.jpg\n",
            "ERROR:downloader:Response status code 403, file https://storage.mainichikirei.jp/images/2016/10/29/20161029dog00m100000000c/001_size6.jpg\n",
            "ERROR:downloader:Response status code 403, file https://storage.mainichikirei.jp/images/2018/03/08/20180308dog00m100007000c/001_size9.jpg\n",
            "ERROR:downloader:Response status code 403, file https://storage.mainichikirei.jp/images/2018/03/13/20180313dog00m100014000c/001_size9.jpg\n",
            "ERROR:downloader:Response status code 403, file https://cdn.v2ph.com/photos/B4EnsHNLLzmAm3vv.jpg\n",
            "ERROR:downloader:Response status code 403, file https://storage.mantan-web.jp/images/2019/06/19/20190619dog00m200072000c/008_size9.jpg\n"
          ]
        }
      ],
      "source": [
        "!pip install icrawler\n",
        "\n",
        "from icrawler.builtin import BingImageCrawler\n",
        "\n",
        "# ①石原さとみ×100\n",
        "crawler = BingImageCrawler(storage={\"root_dir\": \"石原さとみ\"})\n",
        "crawler.crawl(keyword=\"石原さとみ\", max_num=100)\n",
        "\n",
        "from icrawler.builtin import BingImageCrawler\n",
        "\n",
        "# ②新垣結衣×100\n",
        "crawler = BingImageCrawler(storage={\"root_dir\": \"新垣結衣\"})\n",
        "crawler.crawl(keyword=\"新垣結衣\", max_num=100)\n",
        "\n",
        "from icrawler.builtin import BingImageCrawler\n",
        "\n",
        "# ⑤北川景子×100\n",
        "crawler = BingImageCrawler(storage={\"root_dir\": \"北川景子\"})\n",
        "crawler.crawl(keyword=\"北川景子\", max_num=100)\n",
        "\n",
        "from icrawler.builtin import BingImageCrawler\n",
        "\n",
        "# ⑥小松菜奈×100\n",
        "crawler = BingImageCrawler(storage={\"root_dir\": \"小松菜奈\"})\n",
        "crawler.crawl(keyword=\"小松菜奈\", max_num=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os, glob\n",
        "import numpy as np\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "classes = [\"石原さとみ\", \"新垣結衣\", \"北川景子\", \"小松菜奈\"]\n",
        "num_classes = len(classes)\n",
        "image_size = 64\n",
        "num_testdata = 25\n",
        "\n",
        "X_train = []\n",
        "X_test  = []\n",
        "y_train = []\n",
        "y_test  = []\n",
        "\n",
        "for index, classlabel in enumerate(classes):\n",
        "    photos_dir = \"./\" + classlabel\n",
        "    files = glob.glob(photos_dir + \"/*.jpg\")\n",
        "    for i, file in enumerate(files):\n",
        "        image = Image.open(file)\n",
        "        image = image.convert(\"RGB\")\n",
        "        image = image.resize((image_size, image_size))\n",
        "        data = np.asarray(image)\n",
        "        if i < num_testdata:\n",
        "            X_test.append(data)\n",
        "            y_test.append(index)\n",
        "        else:\n",
        "\n",
        "            for angle in range(-20, 20, 5):\n",
        "\n",
        "                img_r = image.rotate(angle)\n",
        "                data = np.asarray(img_r)\n",
        "                X_train.append(data)\n",
        "                y_train.append(index)\n",
        "                img_trains = img_r.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "                data = np.asarray(img_trains)\n",
        "                X_train.append(data)\n",
        "                y_train.append(index)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test  = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test  = np.array(y_test)\n",
        "\n",
        "xy = (X_train, X_test, y_train, y_test)\n",
        "np.save(\"./女優.npy\", xy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "revbS6h5_Oa5",
        "outputId": "387b13b9-34ca-45cf-a932-89dee6627ca3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.optimizers import RMSprop \n",
        "\n",
        "\n",
        "\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "classes = [\"石原さとみ\", \"新垣結衣\", \"北川景子\", \"小松菜奈\"]\n",
        "num_classes = len(classes)\n",
        "image_size = 64\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    X_train, X_test, y_train, y_test = np.load(\"./女優.npy\", allow_pickle=True)\n",
        "    X_train = X_train.astype(\"float\") / 255\n",
        "    X_test  = X_test.astype(\"float\") / 255\n",
        "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "    y_test  = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\n",
        "def train(X, y, X_test, y_test):\n",
        "    model = Sequential()\n",
        "\n",
        "\n",
        "    model.add(Conv2D(32,(3,3), padding='same',input_shape=X.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(32,(3,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    model.add(Conv2D(64,(3,3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64,(3,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.45))\n",
        "    model.add(Dense(4)) \n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    opt = RMSprop(lr=0.00005, decay=1e-6)\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X, y, batch_size=28, epochs=40)\n",
        "    model.save('./cnn.h5')\n",
        "\n",
        "    return model\n",
        "\n",
        "def main():\n",
        "    X_train, y_train, X_test, y_test = load_data()\n",
        "\n",
        "    model = train(X_train, y_train, X_test, y_test)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W3vEzB2Faju",
        "outputId": "333cd123-0b09-4f42-cc9a-7dd41c5cc24e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "63/63 [==============================] - 11s 15ms/step - loss: 1.0756 - accuracy: 0.4352\n",
            "Epoch 2/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.9450 - accuracy: 0.5315\n",
            "Epoch 3/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.8533 - accuracy: 0.5975\n",
            "Epoch 4/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.7620 - accuracy: 0.6439\n",
            "Epoch 5/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.6942 - accuracy: 0.6932\n",
            "Epoch 6/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.6409 - accuracy: 0.7179\n",
            "Epoch 7/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.5755 - accuracy: 0.7546\n",
            "Epoch 8/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.5306 - accuracy: 0.7964\n",
            "Epoch 9/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.4738 - accuracy: 0.8114\n",
            "Epoch 10/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.4399 - accuracy: 0.8337\n",
            "Epoch 11/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3875 - accuracy: 0.8492\n",
            "Epoch 12/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3437 - accuracy: 0.8693\n",
            "Epoch 13/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3137 - accuracy: 0.8882\n",
            "Epoch 14/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2697 - accuracy: 0.9031\n",
            "Epoch 15/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2457 - accuracy: 0.9083\n",
            "Epoch 16/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2160 - accuracy: 0.9214\n",
            "Epoch 17/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.1914 - accuracy: 0.9289\n",
            "Epoch 18/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.1593 - accuracy: 0.9541\n",
            "Epoch 19/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.1400 - accuracy: 0.9541\n",
            "Epoch 20/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.1277 - accuracy: 0.9622\n",
            "Epoch 21/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.1201 - accuracy: 0.9558\n",
            "Epoch 22/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0979 - accuracy: 0.9731\n",
            "Epoch 23/40\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.0949 - accuracy: 0.9690\n",
            "Epoch 24/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0816 - accuracy: 0.9776\n",
            "Epoch 25/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0701 - accuracy: 0.9817\n",
            "Epoch 26/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0614 - accuracy: 0.9822\n",
            "Epoch 27/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0561 - accuracy: 0.9862\n",
            "Epoch 28/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0469 - accuracy: 0.9857\n",
            "Epoch 29/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0512 - accuracy: 0.9851\n",
            "Epoch 30/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0432 - accuracy: 0.9880\n",
            "Epoch 31/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0341 - accuracy: 0.9880\n",
            "Epoch 32/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0327 - accuracy: 0.9914\n",
            "Epoch 33/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0342 - accuracy: 0.9897\n",
            "Epoch 34/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0258 - accuracy: 0.9931\n",
            "Epoch 35/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0266 - accuracy: 0.9908\n",
            "Epoch 36/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0197 - accuracy: 0.9960\n",
            "Epoch 37/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0230 - accuracy: 0.9937\n",
            "Epoch 38/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0181 - accuracy: 0.9931\n",
            "Epoch 39/40\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 0.0164 - accuracy: 0.9954\n",
            "Epoch 40/40\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0151 - accuracy: 0.9960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import sys, os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras.models import load_model\n",
        "\n",
        "imsize = (64, 64)\n",
        "\n",
        "testpic     = \"./画像.jpg\"\n",
        "keras_param = \"./cnn.h5\"\n",
        "\n",
        "def load_image(path):\n",
        "    img = Image.open(path)\n",
        "    img = img.convert('RGB')\n",
        "    img = img.resize(imsize)\n",
        "    img = np.asarray(img)\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "model = load_model(keras_param)\n",
        "img = load_image(testpic)\n",
        "prd = model.predict(np.array([img]))\n",
        "print(prd)\n",
        "prelabel = np.argmax(prd, axis=1)\n",
        "if prelabel == 0:\n",
        "    print(\">>> 石原さとみ\")\n",
        "elif prelabel == 1:\n",
        "    print(\">>> 新垣結衣\")\n",
        "elif prelabel == 2:\n",
        "    print(\">>> 北川景子\")\n",
        "elif prelabel == 3:\n",
        "    print(\">>> 小松菜奈\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX6w3xxNF4EK",
        "outputId": "18e0c34a-5ba8-4e20-e6d4-2ede1ae5c9ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n",
            "[[1.6818819e-07 7.4633710e-02 1.8325117e-13 9.2536616e-01]]\n",
            ">>> 小松菜奈\n"
          ]
        }
      ]
    }
  ]
}